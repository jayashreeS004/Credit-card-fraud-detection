# -*- coding: utf-8 -*-
"""credit card fraud detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15SAjdrZHxObIYJgAE_J-D7PywNoJUkXu
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, roc_auc_score, roc_curve

from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

import warnings
warnings.filterwarnings("ignore")

df = pd.read_excel("credit_card_fraud_dataset.xlsx")

print("Dataset shape:", df.shape)
print(df.head())



sns.countplot(x='Class', data=df)
plt.title("Class Distribution (0 = Not Fraud, 1 = Fraud)")
plt.show()

plt.figure(figsize=(10, 8))
sns.heatmap(df.corr().iloc[:10, :10], cmap='coolwarm', annot=True)
plt.title("Correlation Heatmap (Top 10 Features)")
plt.show()

sns.kdeplot(x=df['Transaction Amount'], hue=df['Class'], fill=True)
plt.title("KDE Plot - Transaction Amount by Class")
plt.show()

X = df.drop('Class', axis=1)
y = df['Class']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, stratify=y, random_state=42
)

# Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)

# XGBoost
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
xgb_model.fit(X_train, y_train)
xgb_pred = xgb_model.predict(X_test)

print("Random Forest Classification Report:")
print(classification_report(y_test, rf_pred))

print("XGBoost Classification Report:")
print(classification_report(y_test, xgb_pred))

rf_probs = rf_model.predict_proba(X_test)[:, 1]
xgb_probs = xgb_model.predict_proba(X_test)[:, 1]

rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)
xgb_fpr, xgb_tpr, _ = roc_curve(y_test, xgb_probs)

rf_auc = roc_auc_score(y_test, rf_probs)
xgb_auc = roc_auc_score(y_test, xgb_probs)

plt.figure(figsize=(10, 6))
plt.plot(rf_fpr, rf_tpr, label=f"Random Forest (AUC = {rf_auc:.2f})")
plt.plot(xgb_fpr, xgb_tpr, label=f"XGBoost (AUC = {xgb_auc:.2f})")
plt.plot([0, 1], [0, 1], "k--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve Comparison")
plt.legend()
plt.grid(True)
plt.show()

summary_df = pd.DataFrame({
    "Model": ["Random Forest", "XGBoost"],
    "Precision": [
        round(classification_report(y_test, rf_pred, output_dict=True)["1"]["precision"], 2),
        round(classification_report(y_test, xgb_pred, output_dict=True)["1"]["precision"], 2)
    ],
    "Recall": [
        round(classification_report(y_test, rf_pred, output_dict=True)["1"]["recall"], 2),
        round(classification_report(y_test, xgb_pred, output_dict=True)["1"]["recall"], 2)
    ],
    "F1-Score": [
        round(classification_report(y_test, rf_pred, output_dict=True)["1"]["f1-score"], 2),
        round(classification_report(y_test, xgb_pred, output_dict=True)["1"]["f1-score"], 2)
    ],
    "AUC Score": [round(rf_auc, 2), round(xgb_auc, 2)]
})

print(summary_df)

from sklearn.metrics import accuracy_score

# Calculate accuracy for both models
rf_accuracy = accuracy_score(y_test, rf_pred)
xgb_accuracy = accuracy_score(y_test, xgb_pred)

# Print accuracy
print(f"Random Forest Accuracy: {rf_accuracy:.2f}")
print(f"XGBoost Accuracy: {xgb_accuracy:.2f}")